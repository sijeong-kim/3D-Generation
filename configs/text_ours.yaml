# training
seed: 42
num_particles: 8
feature_extractor_model_name: facebook/dinov2-base
feature_layer: 11 # 2: early, 5: mid, 11: last

# repulsive loss
lambda_repulsion: 1000 # weight for repulsive loss
adaptive_lambda: False
rep_ratio_target: 40.0
repulsion_type: "wo" # "svgd" or "rlsd" or "wo"
kernel_type: "none" # "rbf" or "cosine"
rbf_beta: 1.0 # beta for rbf kernel
cosine_beta: 1.0 # beta for cosine kernel
cosine_eps_shift: 1e-3 # eps shift for cosine kernel

# guidance
guidance_scale: 50
force_same_t: True # 모든 파티클 동일 t
force_same_noise: True # 모든 파티클 동일 noise
schedule_steps: 1500


# cosine decay
use_cosine_decay: False # use cosine decay for sigma_t
rep_cosine_warmup: 0.0 # 0.0: no warmup, 0.1: warmup
cosine_decay_floor: 0.3 # floor for cosine decay

# sigma_t
# use_sigma_weight: False
# rep_sigma_power: 0.5 # 0.5: sqrt, 1.0: linear, 2.0: square
# gamma_base: 200.0 # ★ γ = gamma_base * σ_t

# visualize
visualize: True
save_rendered_images: False # for visualization
save_rendered_images_interval: 100 # for debugging
save_iid: False # for visualization
visualize_multi_viewpoints: False # for visualization
visualize_multi_viewpoints_interval: 500 # for debugging
visualize_fixed_viewpoint: True # for visualization
visualize_fixed_viewpoint_interval: 100 # for debugging
visualize_graph: False # save graph for debugging
visualize_graph_interval: 100 # for debugging
# save_rep_features: False # save features from different layers
# save_rep_features_interval: 100 # save features from different layers
eval_W: 512
eval_H: 512
eval_radius: 3.0 # not to crop the object adjust the radius

best_step: -1

# metrics
metrics: True
quantitative_metrics_interval: 50
losses_interval: 10
efficiency_interval: 10
kernel_metrics_interval: 10  # interval for logging kernel statistics
enable_lpips: False

# multi-viewpoints (for metrics)
num_views: 8
multi_view_type: "average_views" # "best_views", "average_views", "cross_attention_views"

# save model
save_model: False

# save video snapshot
video_snapshot: False

### Input
# input rgba image path (default to None, can be load in GUI too)
input: 
# input text prompt (default to None, can be input in GUI too)
prompt:
negative_prompt:
# input mesh for stage 2 (auto-search from stage 1 output path if None)
mesh:
# estimated elevation angle for input image 
elevation: 0
# estimated horizontal angle for input image (azimuth)
horizontal: 0
# reference image resolution
ref_size: 256
# density thresh for mesh extraction
density_thresh: 1

### Output
outdir: logs
mesh_format: obj
save_path: ???

### Training
# use mvdream instead of sd 2.1
mvdream: False
# use imagedream
imagedream: False
# use stable-zero123 instead of zero123-xl
stable_zero123: False 
# guidance loss weights (0 to disable)
lambda_sd: 1
lambda_zero123: 0
# warmup rgb supervision for image-to-3d
warmup_rgb_loss: True
# training batch size per iter
batch_size: 1
# training iterations for stage 1
iters: 1000 # 500
schedule_iters: 1500
# whether to linearly anneal timestep
anneal_timestep: True
# training iterations for stage 2
iters_refine: 50
# training camera radius
radius: 2.5
# training camera fovy
fovy: 49.1
# training camera min elevation
min_ver: -30
# training camera max elevation
max_ver: 30
# checkpoint to load for stage 1 (should be a ply file)
load:
# whether allow geom training in stage 2
train_geo: False
# prob to invert background color during training (0 = always black, 1 = always white)
invert_bg_prob: 0.5

### GUI
gui: False
force_cuda_rast: False
# GUI resolution
H: 800
W: 800

### Gaussian splatting
num_pts: 1000 # 5000
sh_degree: 0
position_lr_init: 0.001
position_lr_final: 0.00002
position_lr_delay_mult: 0.02
position_lr_max_steps: 300
feature_lr: 0.01
opacity_lr: 0.05
scaling_lr: 0.005
rotation_lr: 0.005
percent_dense: 0.01
density_start_iter: 0
density_end_iter: 3000
densification_interval: 50
# opacity_reset_interval: 700
opacity_reset_interval: 100000
densify_grad_threshold: 0.01

### Textured Mesh
geom_lr: 0.0001
texture_lr: 0.2
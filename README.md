# 3D-Generation

<div align="center">

# Diversifying 3D Gaussian Splatting with Repulsion Mechanisms

[![Python](https://img.shields.io/badge/Python-3.12.11-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8.0-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-13.0-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

*MSc Individual Project - Imperial College London*

</div>

## ğŸ“‹ Project Overview

This repository presents research on diversifying 3D Gaussian Splatting using repulsion mechanisms. The project extends DreamGaussian by implementing Stein Variational Gradient Descent (SVGD) and Regularized Least-Squares Descent (RLSD) to improve the diversity and quality of generated 3D objects.

### ğŸ¯ Key Features

- **Multiple Repulsion Types**: SVGD, RLSD, and baseline (without repulsion)
- **Kernel Functions**: RBF and Cosine similarity kernels
- **Hyperparameter Optimization**: Automated parameter sweeping and analysis
- **Comprehensive Logging**: Detailed experiment tracking and metadata collection
- **Results Analysis**: Automated generation of Pareto plots, box plots, and comparative analyses

### ğŸ”¬ Research Contributions

- Novel application of particle-based optimization to 3D Gaussian Splatting
- Comparative analysis of different repulsion mechanisms for 3D generation
- Automated hyperparameter optimization framework for 3D generation tasks

## ğŸ“‘ Table of Contents

- [Project Overview](#-project-overview)
- [Development Environment](#development-environment)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Output Structure](#-output-structure)
- [Directory Structure](#directory-structure)
- [References](#-references)

## Development Environment

### âš™ï¸ System Environment
| Component | Specification |
|-----------|---------------|
| **Operating System** | Ubuntu 22.04.1 LTS (Linux 6.2.0-36-generic) |
| **Python Version** | 3.12.11 (conda-forge) |
| **CUDA Version** | 13.0 (Driver: 580.65.06) |
| **PyTorch Version** | 2.8.0+cu128 |
| **cuDNN Version** | 91002 |

### ğŸ–¥ï¸ Hardware Configuration
| Component | Specification |
|-----------|---------------|
| **GPU** | NVIDIA A100 80GB PCIe |
| **GPU Memory** | 81,920 MiB (80GB) |
| **Architecture** | x86_64 |

### ğŸ“¦ Dependencies
| Package | Version |
|---------|---------|
| **PyTorch** | 2.8.0+cu128 |
| **CUDA** | 12.8 |
| **cuDNN** | 91002 |
| **Extensions** | diff-gaussian-rasterization, simple-knn |

### ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/sijeong-kim/3D-Generation.git
cd 3D-Generation

# Setup environment (interactive mode)
bash scripts/envs/setup_interactive.sh

# Or setup environment for SLURM cluster
bash scripts/envs/setup_slurm.sh
```

### âš™ï¸ Default Configuration

| Parameter | Default Value | Description |
|-----------|---------------|-------------|
| **Initial 3D Gaussian Particles** | 1000 | Number of initial Gaussian splats |
| **Densification Interval** | Every 50 steps | Frequency of particle densification |
| **Default Prompt** | "a photo of a hamburger" | Text prompt for 3D generation |
| **Feature Layer** | 11 | CLIP feature extraction layer |
| **Repulsion Type** | 'wo' (without) | Baseline: no repulsion mechanism |



## ğŸš€ Quick Start

### Interactive Mode (Local/Development)

```bash
# Run a single experiment
python main_ours.py --config configs/text_ours.yaml --prompt "a photo of a hamburger"

# Run hyperparameter experiments
bash scripts/experiments/run_exp_interactive.sh exp0_baseline

# Run with dry-run to preview experiments
bash scripts/experiments/run_exp_interactive.sh exp0_baseline --dry-run
```

### SLURM Cluster Mode (Production)

```bash
# Submit experiment job to SLURM
sbatch scripts/experiments/run_exp_sbatch.sh exp0_baseline

# Submit multiple experiments
sbatch scripts/experiments/run_exp_sbatch.sh exp0_baseline exp1_1_lambda_coarse
```

### ğŸ“Š Results Analysis

```bash
# Aggregate and analyze experiment results
python gather_results.py --exp_dir exp/ --output_dir analysis_results/

# Generate specific plot types
python gather_results.py --exp_dir exp/ --output_dir analysis_results/ --plot_type pareto
python gather_results.py --exp_dir exp/ --output_dir analysis_results/ --plot_type boxplot

# Filter experiments by parameters (using key=value directory naming)
ls exp/*/kernel_type=cosine*                    # All cosine kernel experiments
ls exp/*/repulsion_type=svgd*                   # All SVGD experiments
ls exp/*/prompt=hamburger*                      # All hamburger experiments
find exp/ -name "*lambda_repulsion=1000*"       # All experiments with lambda=1000
find exp/ -name "*kernel_type=cosine*" -name "*repulsion_type=rlsd*"  # RLSD + cosine
```

## ğŸ“ Output Structure

### Experiment Results
- **New experiments**: `exp/<experiment_name>/`
- **Legacy experiments**: `logs/<experiment_name>/`
- **SLURM outputs**: `outputs/<SLURM_JOB_ID>/`

### Log Files
- **Job stdout**: `outputs/<SLURM_JOB_ID>/output.out`
- **Job stderr**: `outputs/<SLURM_JOB_ID>/error.err`
- **Experiment logs**: `exp/<experiment_name>/*/stdout.log`, `stderr.log`

## ğŸ”— References
- **DreamGaussian**: [Paper](https://arxiv.org/abs/2309.16553) | [Code](https://github.com/ashawkey/dreamgaussian)
- **3D Gaussian Splatting**: [Paper](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)
- **Stein Variational Gradient Descent**: [Paper](https://arxiv.org/abs/1608.04471)



### Directory Structure

- Project Root Structure
    ```bash
    /vol/bitbucket/sk2324/3D-Generation/
    â”œâ”€â”€ exp/               # ğŸ‘ˆ New experiment results (hp_ours.py)
    â”œâ”€â”€ logs/              # ğŸ‘ˆ Legacy experiment results
    â”œâ”€â”€ outputs/           # ğŸ‘ˆ SLURM job outputs  
    â”œâ”€â”€ configs/           # ğŸ‘ˆ Configuration files
    â”œâ”€â”€ scripts/           # ğŸ‘ˆ SLURM batch scripts
    â”œâ”€â”€ metrics/           # ğŸ‘ˆ Empty (legacy)
    â”œâ”€â”€ hp_ours.py         # ğŸ‘ˆ Main hyperparameter script
    â”œâ”€â”€ gather_results.py  # ğŸ‘ˆ Results aggregation script
    â””â”€â”€ [other project files]
    ```

- **New Experiment Results (`exp/`)** - Enhanced hyperparameter experiments
    ```bash
    exp/experiment_name/                    # e.g., exp0_baseline, exp1_1_lambda_coarse
    â”œâ”€â”€ prompt=hamburger_repulsion_type=svgd_kernel_type=rbf_lambda_repulsion=600/
    â”‚   â”œâ”€â”€ figures/                       # ğŸ‘ˆ Auto-created analysis plots directory
    â”‚   â”‚   â”œâ”€â”€ pareto_plot.png
    â”‚   â”‚   â”œâ”€â”€ boxplot_comparison.png
    â”‚   â”‚   â””â”€â”€ lambda_analysis.png
    â”‚   â”œâ”€â”€ config.yaml                    # ğŸ‘ˆ Experiment configuration
    â”‚   â”œâ”€â”€ stdout.log                     # ğŸ‘ˆ Standard output log
    â”‚   â”œâ”€â”€ stderr.log                     # ğŸ‘ˆ Error log (with auto-tail on failure)
    â”‚   â”œâ”€â”€ run_metadata.yaml              # ğŸ‘ˆ System/environment metadata
    â”‚   â”œâ”€â”€ .done                          # ğŸ‘ˆ Completion marker (prevents re-runs)
    â”‚   â””â”€â”€ ... (other experiment files)
    â”œâ”€â”€ prompt=icecream_repulsion_type=rlsd_kernel_type=cosine_lambda_repulsion=800/
    â”‚   â””â”€â”€ ... (similar structure)
    â””â”€â”€ experiment_summary.yaml            # ğŸ‘ˆ Aggregated results summary
    ```

- **Legacy Experiments Results (`logs/`)** - Original experiment structure
    - Debug Experiments (`run_ours_debug.sh`)
        ```bash
        logs/debug_001/                    # 3 runs total
        â”œâ”€â”€ run_001_[hash]_s42/           # SVGD method
        â”‚   â”œâ”€â”€ metrics/                  # ğŸ‘ˆ CSV files here
        â”‚   â”‚   â”œâ”€â”€ quantitative_metrics.csv
        â”‚   â”‚   â”œâ”€â”€ losses.csv
        â”‚   â”‚   â””â”€â”€ efficiency.csv
        â”‚   â””â”€â”€ experiment_config.json
        â”œâ”€â”€ run_002_[hash]_s42/           # RLSD method  
        â”‚   â””â”€â”€ metrics/
        â””â”€â”€ run_003_[hash]_s42/           # Baseline (wo)
            â””â”€â”€ metrics/
        ```
    - Hyperparameter Tuning (`run_ours_hp.sh`)
        ```bash
        logs/exp_001/                     # Coarse search: 81 runs
        â”œâ”€â”€ run_001_[hash]_s42/           # svgd, layer=2, lambda=1, seed=42
        â”‚   â””â”€â”€ metrics/
        â”œâ”€â”€ run_002_[hash]_s42/           # svgd, layer=2, lambda=100, seed=42
        â”‚   â””â”€â”€ metrics/
        â”œâ”€â”€ ...                           # 79 more combinations
        â””â”€â”€ run_081_[hash]_s456/          # wo, layer=10, lambda=10000, seed=456
            â””â”€â”€ metrics/

        logs/exp_002/                     # Fine search: 35 runs
        logs/exp_003/                     # Generalization: 15 runs  
        logs/exp_004/                     # Efficiency: 36 runs
        logs/exp_005/                     # Multi-view: 36 runs
        ```
- SLURM Job Outputs (`outputs/`)
    ```bash
    outputs/[job_id]/
    â”œâ”€â”€ output.out                    # ğŸ‘ˆ Job stdout
    â””â”€â”€ error.err                     # ğŸ‘ˆ Job stderr/errors
    ```

- Configuration Files (`configs/`)
    ```bash
    configs/
    â”œâ”€â”€ text_ours.yaml               # ğŸ‘ˆ Base configuration
    â”œâ”€â”€ text_ours_debug.yaml         # ğŸ‘ˆ Debug: 3 quick tests
    â””â”€â”€ text_ours_hp.yaml            # ğŸ‘ˆ HP: 203 full experiments
    ```
- execution scripts (`scripts/`)
    ```bash
    scripts/
    â”œâ”€â”€ run_ours_debug.sh            # ğŸ‘ˆ Debug: --mem=16G, 30min
    â””â”€â”€ run_ours_hp.sh               # ğŸ‘ˆ HP: --mem=32G, 48hours
    ```


## Acknowledgements

This project made limited use of AI-assisted coding tools:

- GitHub Copilot (for boilerplate and utility code suggestions)  
- Cursor Agent (for refactoring support and inline documentation)

All AI outputs were critically reviewed and validated by the author.  
The final implementation and experiments were conducted independently by Sijeong Kim.
